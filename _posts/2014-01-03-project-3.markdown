---
layout: default
modal-id: 3
title: "Flight Price Delay Prediction"
date: 2014-07-15
img: plane.png
alt: "Flight Price Delay Prediction"
project-date: "April 2014"
category: "End-to-End Machine Learning"
full_content: |

    <div style="text-align: center;">
        <img src="img/Python-logo-notext.svg" width="7%" alt="python">
        <!-- ------------------------------------- -->
        <img src="https://user-images.githubusercontent.com/1393562/190876627-da2d09cb-5ca0-4480-8eb8-830bdc0ddf64.svg" width="7%" alt="Plus Sign">
        <!-- ------------------------------------- -->
        <img src="img/Jupyter_logo.png" width="7%" alt="jupyter notebook">
        <!-- ------------------------------------- -->
        <img src="https://user-images.githubusercontent.com/1393562/190876627-da2d09cb-5ca0-4480-8eb8-830bdc0ddf64.svg" width="7%" alt="Plus Sign">
        <!-- ------------------------------------- -->
        <img src="img/GitHub_Invertocat_Logo.png" width="7%" alt="github">
        <!-- ------------------------------------- -->
        <img src="https://user-images.githubusercontent.com/1393562/190876627-da2d09cb-5ca0-4480-8eb8-830bdc0ddf64.svg" width="7%" alt="Plus Sign">
        <!-- ------------------------------------- -->
        <img src="img/Databricks_Logo.png" width="15%" alt="databrick">
        <!-- ------------------------------------- -->
        <img src="https://user-images.githubusercontent.com/1393562/190876627-da2d09cb-5ca0-4480-8eb8-830bdc0ddf64.svg" width="7%" alt="Plus Sign">
        <!-- ------------------------------------- -->
        <img src="img/SQL database.png" width="15%" alt="SQL database">
        <!-- ------------------------------------- -->
        <img src="https://user-images.githubusercontent.com/1393562/190876627-da2d09cb-5ca0-4480-8eb8-830bdc0ddf64.svg" width="7%" alt="Plus Sign">
        <!-- ------------------------------------- -->
        <img src="img/pysparks.jpeg" width="15%" alt="pyspark">
        <!-- ------------------------------------- -->
        <img src="https://user-images.githubusercontent.com/1393562/190876627-da2d09cb-5ca0-4480-8eb8-830bdc0ddf64.svg" width="7%" alt="Plus Sign">
        <!-- ------------------------------------- -->
        <img src="img/MLflow-logo-final-black.png" width="15%" alt="MLFlow">
        <!-- ------------------------------------- -->
        
    <div style="text-align: left;">
        <h6 class="section-title">Project Summary:</h6>
        <p>
        Flight delays pose a significant challenge within the airline industry, affecting both passengers' travel experiences and airlines' operational efficiency. As representatives of United Airlines, we recognize that mitigating flight delays is not only crucial for ensuring a smooth journey for our customers but also for maintaining our reputation and optimizing resources. According to data from the Bureau of Transportation Statistics (BTS), approximately 22.09% of United flights experienced delays in 2023. These delays can lead to financial losses, customer dissatisfaction, and operational disruptions, making it imperative for us to take proactive steps to address this issue.
        
        This project focused on reducing United Airlines flight delays by analyzing flight and weather data. Using datasets from the U.S. Department of Transportation and the National Oceanic and Atmospheric Administration (NOAA), the team processed over 12 million records. The main objective was to engineer features and select the optimal model to predict flight delays effectively.</p>
    </div>

    <div style="text-align: left;">
        <h6 class="section-title">Data Summary:</h6>
        <ol>
            <li>Data Size
                <ul>
                    <li>3 months: 1,401,363 rows</li>
                    <li>12 months: 5,811,854 rows</li>
                    <li> 60 months: 12, 926, 912 rows</li>
                </ul>
            </li>
            <li>29 Features
                <ul>
                    <li>6 numeric features</li>
                    <li>6 categorical features</li>
                    <li>7 features from PCA (from 17 numerical features)</li>
                </ul>
            </li>
        </ol>
    </div>

    <div style="text-align: left;">
        <h6 class="section-title">Model Pipeline:</h6>
        <p>The model pipeline consisted of several stages: data preprocessing, feature engineering, model selection, and hyperparameter tuning. Logistic regression, Random Forests, and Gradient Boosting Machines were considered, with the final pipeline optimized for performance and scalability using the entire dataset. The pipeline diagram below outline the entire process mentioned above in further details.</p>
    </div>

    <div style="text-align: center;">
        <img src="img\Projects\Flight Price Delay Prediction\model_pipeline.png" alt="model pipeline diagram" style="max-width: 100%; height: auto;">
    </div>

    <div style="text-align: center;">
    <em>Figure 1: Pipeline digram outlinig the data ingestion, preprocessing, modeling and model evaluation.</em>

    <div style="text-align: left;">
        <h6 class="section-title">Statistical Techniques:</h6>
        <p>Feature engineering techniques, including one-hot encoding and scaling, were applied to ensure model robustness. Various statistical methods, such as time series k-fold cross-validation, bootstrapping, and Principal Component Analysis (PCA), were used to improve model training efficiency and accuracy. Sampling methods, including downsampling and upsampling, were applied to balance the imbalanced dataset.</br>

        Due to the time-dependent nature of the dataset, the training, validation, and testing sets were split in a time series manner. We trained the model on the first three years of data to capture daily, weekly, monthly, and yearly trends. The model was then cross-validated on the fourth year's data, while the fifth year's data was used to evaluate the model's performance.
        </p>
    </div>

    <div style="text-align: left;">
        <h6 class="section-title">Model Performance Evaluation:</h6>

        <p>
        The top four models were Logistic Regression, Random Forest, XGBoost, and Multilayer Perceptron. In Figure 3, the performance of each model is measured by the F1 score.

        The evaluation tables in figure 2 below compared the performance of XGBoost and a Multilayer Perceptron (MLP) model on a 60-month dataset. Both models were trained on the first three years, validated on the fourth, and tested on the fifth year. XGBoost was chosen as the best-performing model due to its higher F1 score and faster runtime compared to MLP.

        XGBoost's initial F1 score plateaued at 75.6%, but after tuning the scale_pos_weight hyperparameter to handle imbalanced data, it improved to 78.3%. Using time series cross-validation, the model's F1 score decreased to 73.3%, but on the held-out test set, it performed satisfactorily with an F1 score of 77.2%.</p>
    </div>

    <div style="text-align: center;">
        <img src="img\Projects\Flight Price Delay Prediction\Xgboost_multipercept_table.png" alt="box-cox-transformation" style="max-width: 100%; height: auto;">
    </div>

    <div style="text-align: center;">
    <em>Figure 2: Model Performance Comparison for XGBoost and Multilayer Perceptron (MLP).</em>

    <div style="text-align: center;">
        <img src="img\Projects\Flight Price Delay Prediction\model_perfomance.png" alt="box-cox-transformation" style="max-width: 100%; height: auto;">
    </div>

    <div style="text-align: center;">
    <em>Figure 3: Models performance evaluation.</em>

    <div style="text-align: left;">
        <h6 class="section-title">Achievements:</h6>
        <p>This project successfully demonstrates the effective use of advanced machine learning techniques, particularly with XGBoost and Multilayer Perceptron (MLP) models, to predict outcomes based on a 60-month dataset. Through careful application of feature engineering, hyperparameter tuning, and sampling methods, the XGBoost model emerged as the superior model due to its higher F1 score and faster runtime.</p>
        <ul>
            <li><strong>Improved Model Performance:</strong> XGBoost achieved an F1 score of 78.3% after hyperparameter tuning, with its final test set F1 score of 77.2% proving its robustness.</li>
            <li><strong>Handling Imbalanced Data:</strong> By introducing the <code>scale_pos_weight</code> hyperparameter, the model efficiently addressed class imbalances, improving classification accuracy.</li>
            <li><strong>Efficient Runtime:</strong> XGBoost demonstrated faster runtimes compared to the MLP model, with 12-18 minutes per run, significantly improving the workflow's efficiency.</li>
            <li><strong>Time Series Cross-Validation:</strong> Despite an initial drop in F1 score during time series cross-validation, the model's satisfactory performance on the held-out test set reinforces its generalization capability.</li>
        </ul>
        <p>Overall, this project showcases the successful implementation of machine learning techniques to handle large, time-dependent datasets, and the effectiveness of XGBoost in achieving high model performance, making it a strong candidate for future predictive modeling tasks.</p>

    </div>

---